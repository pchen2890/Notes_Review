{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- test_train_split: splits the data into 2 groups (test/train)\n",
    "- K-fold Cross Validations: splits data in to different folds (k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = df[\"features\"]\n",
    "y = df[\"price\"]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print \"Score:\", metrics.r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Splits data into k groups\n",
    "- Folds - if k =5, 1 is trained, 2-5 are tests. then 2 is trained and 1,3,4,5 are tests and so forth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = df[\"features\"]\n",
    "y = df[\"price\"]\n",
    "\n",
    "# creates model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "# Make cross validated predictions with 6-fold\n",
    "predictions = cross_val_predict(model, df, y, cv=6)\n",
    "\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(model, df, y, cv=6)\n",
    "print \"Cross-validated scores:\", scores\n",
    "\n",
    "plt.scatter(y, predictions)\n",
    "accuracy = metrics.r2_score(y, predictions)\n",
    "print \"Cross-Predicted Accuracy:\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Regulization to reduct overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " Use Regulization techniques to reduce overfitting to balance bias vs variance\n",
    "- Regularizations\n",
    " - Ridge = c*^2\n",
    "     - better for smaller smaples\n",
    "     - coefficients don't go to 0 but get close\n",
    " - Lasso = |c| \n",
    "     - Better for samples over 1 million \n",
    "     - Have coefficients = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-04/4.2-lab/code/solution-code/solution-code.ipynb\n",
    "- https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-04/4.3-lab/code/solution-code/solution-code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# C = 10(low regulization), 0.1(high regulization)\n",
    "# penalty = (l1 = ridge, l2 = lasso)\n",
    "model = LinearRegression()\n",
    "\n",
    "model = logreg(penalty = 'l1', C = 10.0)  \n",
    "model = logreg(penalty = 'l2', C = .01)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "examine_coefficients(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# OR\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lm_ridge = Ridge().fit(X, y)\n",
    "lm_lasso = Lasso().fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print mean_squared_error(y_test, y_pred)\n",
    "\n",
    "ridge_model = rlm.fit(X, y)\n",
    "predictions = ridge_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Types of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Supervised (Known Values)\n",
    "- White box\n",
    "    - linear (Regression)\n",
    "    - logistic (Regression)\n",
    "    - KNN\n",
    "- Blackbox\n",
    "    - Decision Tree\n",
    "    - Random Forest\n",
    "    - SVM\n",
    "Unsupervised (no predefined groups)\n",
    "- K-means (k-cluster)\n",
    "- Hierarchical\n",
    "- DBSCAN\n",
    "\n",
    "Unknown\n",
    "- Naive Bayes\n",
    "- Dimensionality Reduction Algorithms\n",
    "- Gradient Boost & Adaboost\n",
    "- Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Linear Regression\n",
    "LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn Linear_Regesssion import LinearRegression\n",
    "lm = linear_model.LinearRegression()     # needs to be normally distributed \n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Dervied elements\n",
    "model.coef_                 #grabs coeffiecents\n",
    "model.intercept_            #gives intercept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression\n",
    "LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "- https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-04/2.1-lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LogisticRegression(random_state=45)\n",
    "\n",
    "# fit model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict \n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# predict probability\n",
    "y_pp = model.predict_proba(predict_x)\n",
    "\n",
    "# Dervied elements\n",
    "model.coef_                 #grabs coeffiecents\n",
    "model.intercept_            #gives intercept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# KNN\n",
    "KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1, **kwargs)\n",
    "- https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-04/1.1-lesson\n",
    "- Lab https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-04/1.4-lab/code/solution-code/solution-code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X,y)\n",
    "\n",
    "# predict a list\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Metrics \n",
    "- Regression\n",
    "    - Mean Absolute Error\n",
    "    - Mean Squared Error\n",
    "    - R^2\n",
    "- Classification\n",
    "    - Classification Accuracy\n",
    "    - Logarithmic Loss - a measure of confidence for a prediction by an algorithm. \n",
    "    - Area Under ROC Curve\n",
    "    - Confusion Matrix\n",
    "    - Classification Report\n",
    "    \n",
    "    \n",
    "- Required\n",
    "    - y-test and y-pred\n",
    "- Links\n",
    "    - https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-03/2.1-lesson\n",
    "    - http://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/\n",
    "    - metrics - http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    - roc, classification, confusion - https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-04/2.3-lesson\n",
    "    - ROC - https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-04/2.3-lesson/code/AUC-ROC-codealong.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Regression Metrics\n",
    "- https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-03/2.1-lesson/code/starter-code/Regression-Metrics-and-Loss-Functions-Starter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use MAE when how far off an error is makes little difference\n",
    "# Use MSE/RMSE when more extreme errors should have a large impact\n",
    "# high r^2 for biased models and low r^2 for noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#actual vs predicted\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y_test, y_pred)\n",
    "print \"MAE:\", mean_absolute_error(y_test, y_pred)\n",
    "print \"r2\", r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Classification Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = model.accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Logarithmic Loss\n",
    "from sklearn.metrics import log_loss\n",
    "score = model.log_loss(y_test, proba)\n",
    "\n",
    "# Area Under ROC Curve\n",
    "from sklearn.metrics import roc_auc_score         # correctly predicted? \n",
    "score = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, y_pred)            #Type 1(False Positive, reject null) \n",
    "                                                   #Type 2 (False Negative, accept null)\n",
    "    \n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_test,y_pred)  # precision,recall,f-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accuracy tells us the percent of houses selling for over and under 200k correctly predicted\n",
    "# Precision tells us how well the classifier avoided misclassifying the over 200k houses\n",
    "# Recall tells us how well the classifier correctly identified houses as selling for over 200k\n",
    "# more in depth https://www.crosswise.com/cross-device-learning-center/device-map-accuracy-precision-and-recall/\n",
    "# precision – all guesses are accurate\n",
    "# recall – guessed all points\n",
    "# f1 score – harmonic mean of precision and recall. \n",
    "# reducing threshold improves recall but reduces precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Metric - Cross Val Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# use cross-validation for find score\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Regression\n",
    "score = cross_val_score(model,X_test, y_test,cv=10, scoring = 'accuracy')\n",
    "print \"accuracy:\", scores\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "scores = cross_val_score(model, X_test, y_test, cv=10, scoring = 'mean_squared_error')\n",
    "print \"MSE:\", scores    \n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "scores = cross_val_score(model, X_test, y_test, cv=10, scoring = 'mean_absolute_error')\n",
    "print \"MAE:\", scores    #0 is good because no deviation \n",
    "\n",
    "# R-squared\n",
    "scores = cross_val_score(model, X_test, y_test, cv=10, scoring = 'r2')\n",
    "print \"r2:\", scores    #best fit to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Classification\n",
    "scores = cross_val_score(model, df, y, cv=10, scoring = 'accuracy')  #prediction overall of true positive\n",
    "print \"accuracy:\", scores\n",
    "\n",
    "scores = cross_val_score(model, df, y, cv=10, scoring = 'neg_log_loss')\n",
    "print \"neg_log_loss:\", scores\n",
    "\n",
    "scores = cross_val_score(model, df, y, cv=10, scoring = 'roc_auc')\n",
    "print \"roc_auc:\", scores\n",
    "\n",
    "# no confusion matrics or classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# different types of models\n",
    "http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-06/Model_Comparison_Lab/code/solution-code/solution-code-3_4.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gridsearch\n",
    "https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-04/4.1-lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "gs = GridSearchCV(model, PARAMETERS, cv =10, scoring='accuracy', n_jobs=-1)  \n",
    "gs.fit(X, y)\n",
    "\n",
    "print gs.best_estimator_\n",
    "print gs.best_params_\n",
    "print gs.best_score_\n",
    "\n",
    "# parameters - dictionary of parameters to find best feature\n",
    "#scoring - scoring used to pick best feature\n",
    "# n_jobs - uses all availiable processors\n",
    "\n",
    "# make prediction using gridsearch params\n",
    "prediction = gs.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE Parameters for different Models GRIDSEARCH\n",
    "model = LogisticRegression()\n",
    "PARAMETERS = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "          'penalty': ['l1', 'l2']}\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "PARAMETERS = {'max_depth':[1,2,3,4,5,6], 'max_features':[1,2,3,4], \n",
    "              'max_leaf_nodes':[5,6,7,8,9,10], 'min_samples_leaf':[1,2,3,4],\n",
    "              'min_samples_split':[1,2,3,4]}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'splitter': ['best', 'random'],\n",
    "          'max_depth': [None, 5, 10],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "PARAMETERS = {'n_neighbors': range(2,60)}\n",
    "\n",
    "model = Bagging\n",
    "bagging_params = {'n_estimators': [10, 20],\n",
    "                  'max_samples': [0.7, 1.0],\n",
    "                  'max_features': [0.7, 1.0],\n",
    "                  'bootstrap_features': [True, False]}                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-05/Feature_Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# selects the best feature, grid search is faster\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "def do_k_best(X, y, k=5):\n",
    "    selector = SelectKBest(chi2, k=k)\n",
    "    selected_data = selector.fit_transform(X, y)\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    X_new = pd.DataFrame(selected_data, columns=selected_columns)\n",
    "    return X_new\n",
    "\n",
    "X_new = do_k_best(X, y, 5)\n",
    "do_cm_cr(model, X_new, y, ['benign', 'cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# •\thttps://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-04/2.3-lesson\n",
    "#   logistic regression, classification report, test-train split, AUC/ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# EVERYTHING BELOW THIS NEEDS WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Ensemble Methods - Decision Trees and Bagging??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-06/2.3-lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# bagging creates more models and gives better model score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "bagging = BaggingClassifier(knn, max_samples=0.5, max_features=0.5)\n",
    "\n",
    "bagging = BaggingClassifier(model, max_samples=0.5, max_features=0.5)\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "baggingknn = BaggingClassifier(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# setting up parameters for model\n",
    "# max_depth is the number of tree levels, limiting max_depth helps with overfitting\n",
    "treereg_model = DecisionTreeRegressor(max_depth=3, random_state=1)\n",
    "treereg = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# train model\n",
    "treereg.fit(X_train, y_train) \n",
    "\n",
    "# make predictions\n",
    "preds = treereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-06/1.2-lab/code/solution-code/w6-1.2-%20Decision%20Trees%20Lab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-06/1.2-lab/code/solution-code/w6-1.2-%20Decision%20Trees%20Lab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import class, instantiate estimator, fit with training set\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# set up model parameters\n",
    "treeclf_model = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "\n",
    "\n",
    "# find score\n",
    "scores = cross_val_score(treeclf_model, X, y, cv=3, scoring='mean_squared_error')\n",
    "\n",
    "# train model\n",
    "treeclf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "preds = treeclf.predict(X_test)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Gridsearch with regression\n",
    "# max_depth\tHow many nodes deep can the decision tree go?\n",
    "# max_features\tIs there a cut off to the number of features to use?\n",
    "# max_leaf_nodes\tHow many leaves can be generated per node?\n",
    "# min_samples_leaf\tHow many samples need to be included at a leaf, at a minimum?\n",
    "# min_samples_split\tHow many samples need to be included at a node, at a minimum?\n",
    "PARAMETERS = {'max_depth':[1,2,3,4,5,6], \n",
    "              'max_features':[1,2,3,4], \n",
    "              'max_leaf_nodes':[5,6,7,8,9,10], \n",
    "              'min_samples_leaf':[1,2,3,4],\n",
    "              'min_samples_split':[1,2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Ensemble Methods - Random Forests and Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-06/3.1-lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-06/3.2-lab/code/solution-code/solution-code-3_2.ipynb\n",
    "http://localhost:8888/notebooks/Desktop/DSI-ATX-1/curriculum/04-lessons/week-06/Model_Comparison_Lab/code/solution-code/solution-code-3_4.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "scores = cross_val_score(rf, X, y, cv=cv)\n",
    "scores\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "ab = AdaBoostRegressor()\n",
    "\n",
    "scores = cross_val_score(ab, X, y, cv=cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification and Regression Trees (CARTs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-06/Intro_to_CARTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Scaling & Normalization-model opt  ??? whats transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Standarization 0-1 \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# minMaxScaler min=0 & max=1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# reg scaler - Center to the mean and component wise scale to unit variance.\n",
    "xs = preprocessing.scale(df[\"NOX\"])\n",
    "ys = preprocessing.scale(df[\"TAX\"])\n",
    "\n",
    "\n",
    "\n",
    "# normailzie makes mean to 0 and standard deviation to 1 \n",
    "\n",
    "# Normalize xs and ys with L1 sum\n",
    "xs = preprocessing.normalize(xs, norm='l1')\n",
    "ys = preprocessing.normalize(ys, norm='l1')\n",
    "\n",
    "xs = preprocessing.normalize(xs)\n",
    "ys = preprocessing.normalize(ys)\n",
    "\n",
    "# Normalize xs and ys with L2 sum\n",
    "xs = preprocessing.normalize(xs, norm='l2')\n",
    "ys = preprocessing.normalize(ys, norm='l2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Evaluation and Feature Importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-06/Model_Evaluation_Feature_Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-06.5/SVM%20Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "cvscores = cross_val_score(model, X, y, cv = 5, n_jobs=-1)\n",
    "print \"CV score: {:.3} +/- {:.3}\".format(cvscores.mean(), cvscores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "sklearn.cluster.KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Iterates over its attributes to determine clusters based around centers, known as centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set parameters/fit model\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "clusters = kmeans.fit(X_matrix)\n",
    "\n",
    "# Compute the labels and centroids\n",
    "labels = kmeans.labels_                 #categories of clusters (0,1)\n",
    "centroids = kmeans.cluster_centers_     #means of the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the predicted clusters\n",
    "predY = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute the Silhoutte Score\n",
    "metrics.silhouette_score(y_actual, labels=kmeans.labels_, metric='euclidean')   #how well each of the data points lies within the cluster\n",
    "\n",
    "# high, then the clustering analysis has an appropriate number of clusters. \n",
    "# If the score is low, there are either too many or too few clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# accuracy score\n",
    "metrics.accuracy_score(y_actual, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Classifications report to test the model's accuracy\n",
    "print(metrics.classification_report(y_actual, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix to test the performance of the clustering analysis\n",
    "print(metrics.confusion_matrix(y_actual, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dimensionality Reduction (PCA)\n",
    "PCA - principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "reduces the number of random variabel to only leave the most important ones\n",
    "\n",
    "tool to form a dataset with better features for a classification or regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "eigenvalue tells us how much variance exists in the data\n",
    "\n",
    "eigenvector tells us the direction\n",
    "\n",
    "eigenvectors that has the highest associated eigenvalues are our principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/ga-students/DSI-ATX-1/blob/master/curriculum/04-lessons/week-06.5/PCA/PCA%20Overview.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Split from x and y with only values\n",
    "x = iris.ix[:,0:4].values\n",
    "y = iris.ix[:,4].values\n",
    "\n",
    "# scale data\n",
    "x_standard = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sklearn fastway\n",
    "pcask = PCA(n_components=3)             #number of PC1,PC2, PC3\n",
    "y_sk = pcask.fit_transform(x_standard)\n",
    "\n",
    "# Create a dataframe from the PCA results\n",
    "Ydf = pd.DataFrame(y_sk, columns=[\"PC1\", \"PC2\", \"PCA3\"])\n",
    "\n",
    "\n",
    "#join dataframes together\n",
    "airports2 = airports[['airport', 'year']]\n",
    "airport_pca = airports2.join(Ydf, on=None, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PCA slow way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# THE SLOW WAY\n",
    "covMat1 = np.cov(x_standard.T)\n",
    "eigenValues, eigenVectors = np.linalg.eig(covMat1)\n",
    "\n",
    "# To find the principal components, find the eigenpairs, and sort them from highest to lowest. \n",
    "#higher the eigenpair is the more important the features\n",
    "eigenPairs = [(np.abs(eigenValues[i]), eigenVectors[:,i]) for i in range(len(eigenValues))]\n",
    "eigenPairs.sort()\n",
    "eigenPairs.reverse()\n",
    "for i in eigenPairs:\n",
    "    print(i[0])\n",
    "    \n",
    "\n",
    "# calculate the explained variance\n",
    "totalEigen = sum(eigenValues)\n",
    "varExpl = [(i / totalEigen)*100 for i in sorted(eigenValues, reverse=True)]\n",
    "\n",
    "# calculate the explained variance and the Cumulative explained variance\n",
    "cvarex = np.cumsum(varExpl)\n",
    "cvarex   #the percent the principal compents explins the behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Clustering Aligorthms - K-means, Hierarchical, DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hierarchical Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Top-Down approach\n",
    "# Bottom-up approach (we use)\n",
    "# use for smaller data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# first create matrix with df\n",
    "X = df.as_matrix(columns=None)\n",
    "\n",
    "# gets data to create Dendrogram\n",
    "Z = linkage(X, 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the dendrogram\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Index Numbers')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  \n",
    "    leaf_font_size=8.,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the cluster labels\n",
    "max_d = 15   #limits the number of clusters, visualize and see where to draw the line\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "clusters\n",
    "\n",
    "# plot data and assign the class labels as the color\n",
    "plt.scatter(X[:,0], X[:,6], c=clusters, cmap='prism')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calculate the cophenetic correlation coefficient\n",
    "c, coph_dists = cophenet(Z, pdist(X))\n",
    "\n",
    "# tell us how well the dendrogram has measured the distance between data points\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Truncated Dendeogram\n",
    "plt.title('Truncated Dendrogram')\n",
    "plt.xlabel('Index Numbers')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    truncate_mode='lastp',  \n",
    "    p=15,  \n",
    "    show_leaf_counts=False,  \n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,  \n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "parameters\n",
    "epsilon - maximum distance between two points for them to be considered a cluster \n",
    "minimum points - minimum number of points necessary to form a cluster\n",
    "should scale to data beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the points to form the cluster\n",
    "core_samples = db.core_sample_indices_\n",
    "\n",
    "# cluster labels\n",
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# aim to have the minimum number of points be greater or equal to the amount of dimensions in your data, plus one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# n_components = classes - 1\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.lda import lda\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data; y = iris.target\n",
    "\n",
    "target_names = iris.target_names\n",
    "\n",
    "lda_classifier = lda(n_components=2)\n",
    "lda_x_axis = lda_classifier.fit(X, y).transform(X)\n",
    "\n",
    "color_scheme = ['r', 'g', 'b']\n",
    "\n",
    "for c, i, target_name in zip(color_scheme, [0, 1, 2], target_names):\n",
    "    plt.scatter(lda_x_axis[y == i, 0], lda_x_axis[y == i, 1], c = c, label = target_names)\n",
    "\n",
    "plt.xlabel('First LDA); plt.ylabel('Second LDA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ERROR\n",
    "for i in range(len(df.prices)):\n",
    "    try:\n",
    "        x = ast.literal_eval(df.prices[i])\n",
    "    except ValueError as e:\n",
    "        print e\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helpful Links**\n",
    "\n",
    "models: \n",
    "- https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/\n",
    "- https://www.dezyre.com/article/top-10-machine-learning-algorithms/202\n",
    "- http://chrisalbon.com/\n",
    "\n",
    "Making Hypothesis/Problem Statement\n",
    " - https://github.com/ga-students/DSI-ATX-1/tree/master/curriculum/04-lessons/week-03/4.3-lesson"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
